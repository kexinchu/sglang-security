#!/usr/bin/env python3
"""
Test script for privacy detection mechanism with ZMQ communication
Tests the integration of third-level privacy detection tasks via ZMQ to SGLang scheduler
"""

import time
import zmq
import json
import threading
from typing import Dict, List, Optional
import random

# Mock classes for testing
class MockTreeNode:
    def __init__(self, node_id: str):
        self.node_id = node_id
        self.is_private = False

class MockSamplingParams:
    def __init__(self, temperature=0.1, max_new_tokens=100, top_p=0.9, user_id=None):
        self.temperature = temperature
        self.max_new_tokens = max_new_tokens
        self.top_p = top_p
        self.user_id = user_id

class MockTokenizedGenerateReqInput:
    def __init__(self, rid, input_text, input_ids, sampling_params, **kwargs):
        self.rid = rid
        self.input_text = input_text
        self.input_ids = input_ids
        self.sampling_params = sampling_params
        for key, value in kwargs.items():
            setattr(self, key, value)

class MockBatchStrOut:
    def __init__(self, text):
        self.text = text

def test_privacy_detection_logic():
    """Test the privacy detection logic without ZMQ"""
    print("=== Testing Privacy Detection Logic ===")
    
    # Test data
    test_cases = [
        {
            'context': 'ç”¨æˆ·è¯¢é—®ä¸ªäººä¿¡æ¯',
            'prompt': 'æˆ‘çš„é‚®ç®±æ˜¯ test@example.comï¼Œæ‰‹æœºå·æ˜¯ 13812345678',
            'expected': True
        },
        {
            'context': 'ç”¨æˆ·è¯¢é—®å¤©æ°”',
            'prompt': 'ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ',
            'expected': False
        },
        {
            'context': 'ç”¨æˆ·è¯¢é—®è´¢åŠ¡ä¿¡æ¯',
            'prompt': 'è¯·æä¾›æœ¬å­£åº¦çš„æ”¶å…¥æ•°æ®',
            'expected': True
        },
        {
            'context': 'ç”¨æˆ·è¯¢é—®é¡¹ç›®ä¿¡æ¯',
            'prompt': 'æˆ‘ä»¬åœ¨è¿›è¡Œproject_alphaçš„å¼€å‘',
            'expected': True
        }
    ]
    
    def build_llm_detection_prompt(context, prompt):
        """æ„å»ºLLMéšç§æ£€æµ‹çš„prompt"""
        detection_prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬æ˜¯å¦åŒ…å«éšç§ä¿¡æ¯ã€‚è¯·åªå›ç­”"æ˜¯"æˆ–"å¦"ã€‚

ä¸Šä¸‹æ–‡: {context}
æ–‡æœ¬: {prompt}

è¯·åˆ¤æ–­è¿™ä¸ªæ–‡æœ¬æ˜¯å¦åŒ…å«éšç§ä¿¡æ¯ï¼ˆå¦‚ä¸ªäººä¿¡æ¯ã€æ•æ„Ÿæ•°æ®ã€å¯†ç ç­‰ï¼‰ã€‚åªå›ç­”"æ˜¯"æˆ–"å¦"ã€‚

å›ç­”:"""
        return detection_prompt
    
    def parse_llm_privacy_result(llm_response):
        """è§£æLLMçš„éšç§æ£€æµ‹ç»“æœ"""
        if not llm_response:
            return False
        
        # æ¸…ç†å“åº”æ–‡æœ¬
        response_clean = llm_response.strip().lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«"æ˜¯"ã€"private"ã€"éšç§"ç­‰å…³é”®è¯
        private_keywords = ['æ˜¯', 'yes', 'private', 'éšç§', 'æ•æ„Ÿ', 'sensitive']
        public_keywords = ['å¦', 'no', 'public', 'å…¬å¼€', 'ééšç§']
        
        for keyword in private_keywords:
            if keyword in response_clean:
                return True
        
        for keyword in public_keywords:
            if keyword in response_clean:
                return False
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„å…³é”®è¯ï¼Œæ ¹æ®å“åº”é•¿åº¦å’Œå†…å®¹åˆ¤æ–­
        # é€šå¸¸"æ˜¯"çš„å›ç­”æ¯”è¾ƒç®€çŸ­
        if len(response_clean) <= 3:
            return True  # çŸ­å›ç­”é€šå¸¸æ˜¯"æ˜¯"
        
        return False  # é»˜è®¤è®¤ä¸ºæ˜¯å…¬å¼€çš„
    
    # Test each case
    for i, case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}:")
        print(f"  ä¸Šä¸‹æ–‡: {case['context']}")
        print(f"  æç¤ºè¯: {case['prompt']}")
        
        # Build prompt
        prompt = build_llm_detection_prompt(case['context'], case['prompt'])
        print(f"  ç”Ÿæˆçš„æ£€æµ‹prompt: {prompt[:100]}...")
        
        # Mock LLM response based on expected result
        mock_response = "æ˜¯" if case['expected'] else "å¦"
        print(f"  æ¨¡æ‹ŸLLMå“åº”: {mock_response}")
        
        # Parse result
        result = parse_llm_privacy_result(mock_response)
        print(f"  è§£æç»“æœ: {'ç§æœ‰' if result else 'å…¬å¼€'}")
        print(f"  æœŸæœ›ç»“æœ: {'ç§æœ‰' if case['expected'] else 'å…¬å¼€'}")
        print(f"  æµ‹è¯•ç»“æœ: {'âœ… é€šè¿‡' if result == case['expected'] else 'âŒ å¤±è´¥'}")

def test_zmq_communication():
    """Test ZMQ communication for privacy detection requests"""
    print("\n=== Testing ZMQ Communication ===")
    
    # Create ZMQ context
    context = zmq.Context()
    
    # Create sockets
    sender = context.socket(zmq.PUSH)
    sender.bind("tcp://127.0.0.1:5555")
    
    receiver = context.socket(zmq.PULL)
    receiver.connect("tcp://127.0.0.1:5555")
    
    # Test data
    test_request = {
        'rid': f"PRIVACY_DETECTION_LLM_test_{int(time.time())}",
        'input_text': 'è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬æ˜¯å¦åŒ…å«éšç§ä¿¡æ¯',
        'input_ids': [ord(c) for c in 'è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬æ˜¯å¦åŒ…å«éšç§ä¿¡æ¯'],
        'sampling_params': MockSamplingParams(user_id=123),
        'return_logprob': False,
        'stream': False
    }
    
    print(f"å‘é€æµ‹è¯•è¯·æ±‚: {test_request['rid']}")
    
    # Send request
    sender.send_pyobj(test_request)
    
    # Receive request
    received_request = receiver.recv_pyobj()
    
    print(f"æ¥æ”¶åˆ°çš„è¯·æ±‚: {received_request['rid']}")
    print(f"è¯·æ±‚å†…å®¹: {received_request['input_text']}")
    print(f"ç”¨æˆ·ID: {received_request['sampling_params'].user_id}")
    
    # Check if it's a privacy detection request
    is_privacy_detection = received_request['rid'].startswith("PRIVACY_DETECTION_LLM_")
    print(f"æ˜¯å¦ä¸ºéšç§æ£€æµ‹è¯·æ±‚: {'æ˜¯' if is_privacy_detection else 'å¦'}")
    
    # Clean up
    sender.close()
    receiver.close()
    context.term()
    
    print("âœ… ZMQé€šä¿¡æµ‹è¯•é€šè¿‡")

def test_priority_handling():
    """Test priority handling for privacy detection requests"""
    print("\n=== Testing Priority Handling ===")
    
    # Mock waiting queue
    waiting_queue = []
    
    def add_request_to_queue(req, is_privacy_detection=False):
        """æ¨¡æ‹Ÿæ·»åŠ è¯·æ±‚åˆ°é˜Ÿåˆ—"""
        if is_privacy_detection:
            waiting_queue.insert(0, req)
            print(f"é«˜ä¼˜å…ˆçº§è¯·æ±‚ {req['rid']} æ’å…¥åˆ°é˜Ÿåˆ—å‰é¢")
        else:
            waiting_queue.append(req)
            print(f"æ™®é€šè¯·æ±‚ {req['rid']} æ·»åŠ åˆ°é˜Ÿåˆ—æœ«å°¾")
    
    # Add some test requests
    add_request_to_queue({'rid': 'normal_request_1', 'priority': 0}, False)
    add_request_to_queue({'rid': 'normal_request_2', 'priority': 0}, False)
    add_request_to_queue({'rid': 'PRIVACY_DETECTION_LLM_test_1', 'priority': 1}, True)
    add_request_to_queue({'rid': 'normal_request_3', 'priority': 0}, False)
    add_request_to_queue({'rid': 'PRIVACY_DETECTION_LLM_test_2', 'priority': 1}, True)
    
    print(f"\né˜Ÿåˆ—é¡ºåº:")
    for i, req in enumerate(waiting_queue):
        priority_mark = "ğŸ”’" if req['rid'].startswith("PRIVACY_DETECTION_LLM_") else "ğŸ“"
        print(f"  {i+1}. {priority_mark} {req['rid']}")
    
    # Verify priority order
    privacy_requests = [req for req in waiting_queue if req['rid'].startswith("PRIVACY_DETECTION_LLM_")]
    normal_requests = [req for req in waiting_queue if not req['rid'].startswith("PRIVACY_DETECTION_LLM_")]
    
    print(f"\néšç§æ£€æµ‹è¯·æ±‚æ•°é‡: {len(privacy_requests)}")
    print(f"æ™®é€šè¯·æ±‚æ•°é‡: {len(normal_requests)}")
    
    # Check if privacy requests are at the front
    first_two_are_privacy = all(
        req['rid'].startswith("PRIVACY_DETECTION_LLM_") 
        for req in waiting_queue[:2]
    )
    
    print(f"å‰ä¸¤ä¸ªè¯·æ±‚æ˜¯å¦ä¸ºéšç§æ£€æµ‹: {'æ˜¯' if first_two_are_privacy else 'å¦'}")
    print(f"ä¼˜å…ˆçº§å¤„ç†æµ‹è¯•: {'âœ… é€šè¿‡' if first_two_are_privacy else 'âŒ å¤±è´¥'}")

def test_batch_processing():
    """Test batch processing of privacy detection requests"""
    print("\n=== Testing Batch Processing ===")
    
    # Mock batch processing
    def process_batch(requests):
        """æ¨¡æ‹Ÿæ‰¹å¤„ç†"""
        privacy_requests = []
        normal_requests = []
        
        for req in requests:
            if req['rid'].startswith("PRIVACY_DETECTION_LLM_"):
                privacy_requests.append(req)
            else:
                normal_requests.append(req)
        
        return privacy_requests, normal_requests
    
    # Test batch
    test_batch = [
        {'rid': 'PRIVACY_DETECTION_LLM_batch_1', 'priority': 1},
        {'rid': 'normal_batch_1', 'priority': 0},
        {'rid': 'PRIVACY_DETECTION_LLM_batch_2', 'priority': 1},
        {'rid': 'normal_batch_2', 'priority': 0},
        {'rid': 'PRIVACY_DETECTION_LLM_batch_3', 'priority': 1},
    ]
    
    print("æµ‹è¯•æ‰¹æ¬¡:")
    for req in test_batch:
        priority_mark = "ğŸ”’" if req['rid'].startswith("PRIVACY_DETECTION_LLM_") else "ğŸ“"
        print(f"  {priority_mark} {req['rid']}")
    
    # Process batch
    privacy_requests, normal_requests = process_batch(test_batch)
    
    print(f"\nåˆ†ç±»ç»“æœ:")
    print(f"éšç§æ£€æµ‹è¯·æ±‚: {len(privacy_requests)} ä¸ª")
    for req in privacy_requests:
        print(f"  ğŸ”’ {req['rid']}")
    
    print(f"æ™®é€šè¯·æ±‚: {len(normal_requests)} ä¸ª")
    for req in normal_requests:
        print(f"  ğŸ“ {req['rid']}")
    
    # Verify results
    expected_privacy_count = 3
    expected_normal_count = 2
    
    print(f"\néªŒè¯ç»“æœ:")
    print(f"éšç§æ£€æµ‹è¯·æ±‚æ•°é‡: {len(privacy_requests)} (æœŸæœ›: {expected_privacy_count})")
    print(f"æ™®é€šè¯·æ±‚æ•°é‡: {len(normal_requests)} (æœŸæœ›: {expected_normal_count})")
    
    success = (len(privacy_requests) == expected_privacy_count and 
               len(normal_requests) == expected_normal_count)
    
    print(f"æ‰¹å¤„ç†æµ‹è¯•: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}")

def test_integration():
    """Test the complete integration"""
    print("\n=== Testing Complete Integration ===")
    
    # Simulate the complete workflow
    def simulate_privacy_detection_workflow():
        """æ¨¡æ‹Ÿå®Œæ•´çš„éšç§æ£€æµ‹å·¥ä½œæµç¨‹"""
        
        # 1. Create privacy detection task
        task_data = {
            'node_id': 'test_node_123',
            'context': 'ç”¨æˆ·è¯¢é—®ä¸ªäººä¿¡æ¯',
            'prompt': 'æˆ‘çš„é‚®ç®±æ˜¯ test@example.comï¼Œæ‰‹æœºå·æ˜¯ 13812345678'
        }
        
        print(f"1. åˆ›å»ºéšç§æ£€æµ‹ä»»åŠ¡: {task_data['node_id']}")
        
        # 2. Build detection prompt
        detection_prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬æ˜¯å¦åŒ…å«éšç§ä¿¡æ¯ã€‚è¯·åªå›ç­”"æ˜¯"æˆ–"å¦"ã€‚

ä¸Šä¸‹æ–‡: {task_data['context']}
æ–‡æœ¬: {task_data['prompt']}

è¯·åˆ¤æ–­è¿™ä¸ªæ–‡æœ¬æ˜¯å¦åŒ…å«éšç§ä¿¡æ¯ï¼ˆå¦‚ä¸ªäººä¿¡æ¯ã€æ•æ„Ÿæ•°æ®ã€å¯†ç ç­‰ï¼‰ã€‚åªå›ç­”"æ˜¯"æˆ–"å¦"ã€‚

å›ç­”:"""
        
        print(f"2. æ„å»ºæ£€æµ‹prompt: {detection_prompt[:50]}...")
        
        # 3. Create LLM request
        llm_request = {
            'rid': f"PRIVACY_DETECTION_LLM_{task_data['node_id']}_{int(time.time())}",
            'input_text': detection_prompt,
            'input_ids': [ord(c) for c in detection_prompt[:100]],
            'sampling_params': MockSamplingParams(user_id=task_data['node_id']),
            'is_privacy_detection': True,
            'priority': 1
        }
        
        print(f"3. åˆ›å»ºLLMè¯·æ±‚: {llm_request['rid']}")
        
        # 4. Add to queue with priority
        waiting_queue = []
        waiting_queue.insert(0, llm_request)  # High priority
        print(f"4. æ·»åŠ åˆ°é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—")
        
        # 5. Process request
        processed_request = waiting_queue.pop(0)
        print(f"5. å¤„ç†è¯·æ±‚: {processed_request['rid']}")
        
        # 6. Simulate LLM response
        mock_llm_response = "æ˜¯"  # Mock response indicating privacy detected
        print(f"6. LLMå“åº”: {mock_llm_response}")
        
        # 7. Parse result
        is_private = mock_llm_response.strip().lower() in ['æ˜¯', 'yes', 'private', 'éšç§']
        print(f"7. è§£æç»“æœ: {'ç§æœ‰' if is_private else 'å…¬å¼€'}")
        
        # 8. Return result
        result = {
            'status': 'success',
            'privacy': 'private' if is_private else 'public',
            'confidence': 0.85,
            'node_id': task_data['node_id'],
            'detection_level': 'third_level',
            'llm_response': mock_llm_response
        }
        
        print(f"8. è¿”å›ç»“æœ: {result}")
        
        return result
    
    # Run integration test
    result = simulate_privacy_detection_workflow()
    
    # Verify result
    expected_result = {
        'status': 'success',
        'privacy': 'private',
        'confidence': 0.85,
        'node_id': 'test_node_123',
        'detection_level': 'third_level'
    }
    
    print(f"\néªŒè¯é›†æˆç»“æœ:")
    for key in expected_result:
        if key in result and result[key] == expected_result[key]:
            print(f"  âœ… {key}: {result[key]}")
        else:
            print(f"  âŒ {key}: æœŸæœ› {expected_result.get(key)}, å®é™… {result.get(key)}")
    
    success = all(
        result.get(key) == expected_result.get(key) 
        for key in expected_result
    )
    
    print(f"\né›†æˆæµ‹è¯•: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}")

def main():
    """Run all tests"""
    print("ğŸ”’ Privacy Detection Mechanism Test Suite")
    print("=" * 50)
    
    try:
        # Run all tests
        test_privacy_detection_logic()
        test_zmq_communication()
        test_priority_handling()
        test_batch_processing()
        test_integration()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("éšç§æ£€æµ‹æœºåˆ¶å·²æˆåŠŸé›†æˆåˆ°SGLangè°ƒåº¦å™¨ä¸­")
        print("æ”¯æŒé€šè¿‡ZMQå‘é€ç¬¬ä¸‰çº§éšç§æ£€æµ‹ä»»åŠ¡")
        print("æ”¯æŒé«˜ä¼˜å…ˆçº§å¤„ç†å’Œé˜Ÿåˆ—ç®¡ç†")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 